@misc{universalFER,
title={The Seven Universal Emotions We Wear On Our Face},
author={CBC},
publisher={CBC docs},
howpublished = {\url{https://www.cbc.ca/natureofthings/features/the-seven-universal-emotions-we-wear-on-our-face}},
note = "[First Accessed: 25-03-2022]",
}

@misc{denseNet,
title={A visualization of the DenseNet-201 architecture.},
author={Andrew C. Li},
publisher={ResearchGate},
howpublished = {\url{https://www.researchgate.net/publication/344143047_COVID-19_Detection_From_Chest_Radiographs_Using_Machine_Learning_and_Convolutional_Neural_Networks}},
note = "[First Accessed: 25-03-2022]",
}
@misc{resnet,
title={Skip (shortcut) connection},
publisher={Geeks for geeks},
howpublished = {\url{https://www.geeksforgeeks.org/residual-networks-resnet-deep-learning/}},
note = "[First Accessed: 25-03-2022]",
}
@misc{vgg19,
title={Illustration of fine-tuned VGG19 pre-trained CNN model},
author={Mohammad Motiur Rahman},
publisher={ResearchGate},
howpublished = {\url{https://www.researchgate.net/publication/342815128_machine_learning_knowledge_extraction_Focal_Liver_Lesion_Detection_in_Ultrasound_Image_Using_Deep_Feature_Fusions_and_Super_Resolution}},
note = "[First Accessed: 25-03-2022]",
}
@misc{cnnSequence,
title={A Comprehensive Guide to Convolutional Neural Networks},
author={Sumit Saha},
publisher={Medium},
howpublished = {\url{https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53}},
note = "[First Accessed: 25-03-2022]",
}
@misc{convolutionLayer,
title={Understanding Deep Self-attention Mechanism in Convolution Neural Networks},
author={Shuchen Du},
publisher={Medium},
howpublished = {\url{https://medium.com/ai-salon/understanding-deep-self-attention-mechanism-in-convolution-neural-networks-e8f9c01cb251}},
note = "[First Accessed: 25-03-2022]",
}
@misc{poolingLayer,
title={Deep Neural Networks on Chip},
author={Imran Ali},
publisher={ResearchGate},
howpublished = {\url{https://www.researchgate.net/publication/340812216_Deep_Neural_Networks_on_Chip_-_A_Survey}},
note = "[First Accessed: 25-03-2022]",
}
@misc{fullyConnected,
title={Fully Connected layer},
publisher={O'reilly},
howpublished = {\url{https://www.oreilly.com/library/view/machine-learning-projects/9781788994590/5961f28e-eb19-42c9-bd69-8bf23d00fa78.xhtml}},
note = "[First Accessed: 25-03-2022]",
}
@misc{ferData,
title={Challenges in Representation Learning: Facial Expression Recognition Challenge},
author={Kaggle},
publisher={Kaggle},
howpublished = {\url{https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge}},
note = "[First Accessed: 25-03-2022]",
}
@misc{ckData,
title={The Extended Cohn-Kanade Dataset (CK+): A complete dataset for action unit and emotion-specified expression},
author={IEEE},
publisher={IEEE},
howpublished = {\url{https://ieeexplore.ieee.org/document/5543262}},
note = "[First Accessed: 25-03-2022]",
}
@misc{affectNetData,
title={AffectNet: A Database for Facial Expression, Valence, and Arousal Computing in the Wild},
author={Mohammad H. Mahoor},
publisher={IEEE},
howpublished = {\url{https://arxiv.org/pdf/1708.03985.pdf}},
note = "[First Accessed: 25-03-2022]",
}
@misc{googleData,
title={Google facial expression comparison dataset},
author={Raviteja Vemulapalli},
publisher={Google Research},
howpublished = {\url{https://research.google/tools/datasets/google-facial-expression/}},
note = "[First Accessed: 25-03-2022]",
}
@misc{courseraProject,
title={Coursera FER guided project},
author={Snehan Kekre},
publisher={Coursera},
howpublished = {\url{https://www.coursera.org/projects/facial-expression-recognition-keras?fbclid=IwAR2OdBwnAxXI0CdXviaT6qDEqRxq2K-t54RpHJnyFJ6RfqWy46kY8KKfYUY}},
note = "[First Accessed: 09-04-2022]",
}
@misc{CourseraArchitecture,
title={Challenges in representation learning: A report on three machine learning contests},
author={Ian J.Goodfellow},
publisher={ELSEVIER},
howpublished = {\url{https://doi.org/10.1016/j.neunet.2014.09.005}},
note = "[First Accessed: 09-04-2022]",
}
@misc{deepface,
title={DeepFace source code},
author={Sefik Ilkin Serengil},
publisher={Github},
howpublished = {\url{https://github.com/serengil/deepface}},
note = "[First Accessed: 09-04-2022]",
}
@misc{deepfacearticle,
title={Facial Expression Recognition with Keras},
author={Sefik Ilkin Serengil},
publisher={sefiks.com},
howpublished = {\url{https://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/?fbclid=IwAR3ThUAlrbF2kngnRnzmR_TkWum90eu_GrgtK7eGoSjSYyQUvOweUGde2M8}},
note = "[First Accessed: 09-04-2022]",
}
@misc{vgg19article,
title={Pre-Trained Convolutional Neural Network Features for Facial Expression Recognition},
author={Aravind Ravi},
publisher={IEEE},
howpublished = {\url{https://arxiv.org/ftp/arxiv/papers/1812/1812.06387.pdf}},
note = "page 2, 2018 [First Accessed: 09-04-2022]",
}
@misc{resnet50article,
title={Facial expression recognition via ResNet-50},
author={BinLi},
publisher={KeAi},
howpublished = {\url{https://www.sciencedirect.com/science/article/pii/S2666307421000073#sec0002}},
note = "[First Accessed: 09-04-2022]",
}
@misc{blissify,
title={Blissify chrome extension},
publisher={Google Chrome},
howpublished = {\url{https://chrome.google.com/webstore/detail/blissify/ggjcnaliaijbojobhififalikcdmedkd?hl=en}},
note = "[First Accessed: 09-04-2022]",
}
@misc{xeoma,
title={Xeoma},
author = {Felenasoft},
publisher={Felenasoft Home},
howpublished = {\url{https://felenasoft.com/xeoma/en/articles/emotions-recognition-in-xeoma/}},
year={2020},
note = "[First Accessed: 09-04-2022]",
}
@misc{4littletrees,
title={4 little trees},
publisher={Find Solution AI},
howpublished = {\url{https://www.4littletrees.com/}},
note = "[First Accessed: 09-04-2022]",
}
@misc{morphcast,
title={Morphcast},
publisher={Morphcast},
howpublished = {\url{https://www.morphcast.com/}},
note = "[First Accessed: 09-04-2022]",
}


@misc{googlecolab,
title={Google Colab : Le guide Ultime},
author={Henri Michel},
publisher={ledatascientist.com},
howpublished = {\url{https://ledatascientist.com/google-colab-le-guide-ultime/}},
note = "[First Accessed: 15-05-2022]",
}

@misc{python,
howpublished = {\url{https://www.python.org/about/}},
note = "[First Accessed: 02-04-2022]",
title = {{Python}},
}

@misc{keras,
howpublished = {\url{https://keras.io/}},
note = "[First Accessed: 02-04-2022]",
title = {{Keras}},
}

@misc{matplotlib,
howpublished = {\url{https://pypi.org/project/matplotlib/}},
note = "[First Accessed: 02-04-2022]",
title = {{Matplotlib}},
}


@misc{livelossplot,
howpublished = {\url{https://pypi.org/project/livelossplot/}},
note = "[First Accessed: 12-05-2022]",
title = {{Livelossplot}},
}

@misc{tfjs,
howpublished = {\url{https://github.com/tensorflow/tfjs}},
note = "[First Accessed: 31-05-2022]",
title = {{Tensorflow Js}},
}

@misc{faceapi,
howpublished = {\url{https://medium.com/theleanprogrammer/face-api-js-a-way-to-build-face-recognition-system-in-browser-c1f4ac922657}},
note = "[First Accessed: 31-05-2022]",
title = {{Face API}},
}

@misc{NodeJS,
howpublished = {\url{https://nodejs.org/en/}},
note = "[First Accessed: 31-05-2022]",
title = {{NodeJS}},
}
@misc{VisualStudioCode,
howpublished = {\url{https://code.visualstudio.com/docs}},
note = "[First Accessed: 31-05-2022]",
title = {{Visual Code Studio}},
}
